{"cells":[{"cell_type":"markdown","metadata":{"id":"A5LJ6VU3ZiJ1"},"source":["## 1.0 Importando bibliotecas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JOTAi0A_ZlDF"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import random\n","import gc\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.ensemble import GradientBoostingClassifier\n","# Definindo a semente\n","random.seed(123)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F2B9y9RyIeVp","executionInfo":{"status":"ok","timestamp":1758992679092,"user_tz":180,"elapsed":21827,"user":{"displayName":"Mateus Almeida","userId":"01982828616956278499"}},"outputId":"eb1faf18-eea1-4426-a437-37e80b068fe6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"-f4j4HyoXhuG"},"source":["## 2.0 Funções auxiliares"]},{"cell_type":"markdown","source":["Esse conjunto de funções implementa um pipeline de pré-processamento e seleção de variáveis para modelos de crédito. Em resumo: generate_metadata cria um DataFrame pandas com metadados básicos (tipo, quantidade e % de nulos, cardinalidade) para cada coluna; remove_highly_correlated_features calcula a matriz de correlação e remove colunas com correlação absoluta acima de um threshold; amostragem retorna uma amostra aleatória do DataFrame; variancia transforma atributos categóricos em numéricos (LabelEncoder), padroniza (StandardScaler) e aplica VarianceThreshold para eliminar features com baixa variância; feature_importance faz uma amostragem (n=85.000), trata missings (SimpleImputer), aplica encoding para categóricas, treina um GradientBoostingClassifier e retorna um DataFrame com as features cujo peso de importância é > 0; por fim, vars_selection orquestra o processo: filtra variáveis sufX_publico, amostra os dados, gera metadados, filtra por preenchimento, remove features altamente correlacionadas, aplica seleção por variância e retorna as importâncias via feature_importance. Observações práticas: é preciso garantir que todas as bibliotecas (pandas, numpy, sklearn) estejam importadas; atentar para memória/tempo em amostras grandes; vars_selection chama pod_academy_generate_metadata (que não está definido no trecho) — substitua por generate_metadata ou pela função desejada; e ajuste tamanho_amostra/n na amostragem conforme a disponibilidade de recursos."],"metadata":{"id":"icIeoIGA_sPN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZdS3WDDXXJB"},"outputs":[],"source":["# Metadados referente ao conjunto de dados\n","def generate_metadata(dataframe):\n","    \"\"\"\n","    Gera um dataframe contendo metadados das colunas do dataframe fornecido.\n","\n","    :param dataframe: DataFrame para o qual os metadados serão gerados.\n","    :return: DataFrame contendo metadados.\n","    \"\"\"\n","\n","    # Coleta de metadados básicos\n","    metadata = pd.DataFrame({\n","        'nome_variavel': dataframe.columns,\n","        'tipo': dataframe.dtypes,\n","        'qt_nulos': dataframe.isnull().sum(),\n","        'percent_nulos': round((dataframe.isnull().sum() / len(dataframe))* 100,2),\n","        'cardinalidade': dataframe.nunique(),\n","    })\n","    metadata=metadata.sort_values(by='percent_nulos',ascending=False)\n","    metadata = metadata.reset_index(drop=True)\n","\n","    return metadata\n","\n","def remove_highly_correlated_features(df, threshold):\n","  # Calculate the correlation matrix\n","  corr_matrix = df.corr().abs()\n","\n","  # Select the upper triangle of the correlation matrix\n","  upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n","\n","  # Identify columns to drop based on the threshold\n","  to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n","\n","  # Drop the columns\n","  df_reduced = df.drop(columns=to_drop)\n","\n","  return df_reduced, to_drop\n","\n","def amostragem(df,tamanho_amostra):\n","  amostra = df.sample(n=tamanho_amostra,random_state=42)\n","  return amostra\n","\n","def variancia(table_01, threshold):\n","    cat_attributes = table_01.select_dtypes(include='object')\n","    num_attributes = table_01.select_dtypes(exclude='object')\n","\n","    # Preparação dos dados\n","\n","    # Create a label encoder\n","    label_encoder = LabelEncoder()\n","\n","    # Fit and transform the data\n","    for obj in cat_attributes.columns:\n","        cat_attributes[obj] = label_encoder.fit_transform(cat_attributes[obj].astype(str))\n","\n","    table_final = pd.concat([num_attributes,cat_attributes],axis=1)\n","\n","    # Scaler\n","    scaler = StandardScaler()\n","\n","    table_final_02 = scaler.fit_transform(table_final)\n","\n","    table_final_03 = pd.DataFrame(table_final_02,columns=table_01.columns)\n","\n","    selector = VarianceThreshold(threshold)\n","    selector.fit_transform(table_final_03)\n","\n","    # Colunas selecionadas\n","    selected_features = table_final_03.columns[selector.get_support()]\n","\n","    # Manter apenas features selecionadas\n","    table_final_03_select01 = table_final_03[selected_features]\n","\n","    return table_final_03_select01\n","\n","def feature_importance(df):\n","  # Amostragem\n","  amostra = df.sample(n=85000,random_state=42)\n","\n","  X = amostra.drop(columns=['SK_ID_CURR_publico','TARGET_publico'])\n","  y = amostra.TARGET_publico\n","  id = amostra.SK_ID_CURR_publico\n","\n","  # Tratamento de missings\n","  from sklearn.impute import SimpleImputer\n","  imputer_num = SimpleImputer(strategy='mean')\n","  imputer_cat = SimpleImputer(strategy='most_frequent')\n","  cat_attributes = X.select_dtypes(include='object')\n","  num_attributes = X.select_dtypes(exclude='object')\n","  num_imputed = imputer_num.fit_transform(num_attributes)\n","  cat_imputed = imputer_cat.fit_transform(cat_attributes)\n","\n","  df_num = pd.DataFrame(num_imputed,columns=num_attributes.columns)\n","  df_cat = pd.DataFrame(cat_imputed,columns=cat_attributes.columns)\n","\n","  # Aplicação de encoding\n","  label_encoder = LabelEncoder()\n","\n","  # Fit and transform the data\n","  for obj in cat_attributes.columns:\n","      df_cat[obj] = label_encoder.fit_transform(df_cat[obj].astype(str))\n","\n","  y.index = df_num.index\n","  id.index = df_num.index\n","  df_tratado = pd.concat([df_num,df_cat,y],axis=1)\n","\n","  X = df_tratado.drop(columns='TARGET_publico')\n","  y = df_tratado.TARGET_publico\n","\n","  # Treino utilizando o Gradient Boosting\n","  algoritmo = GradientBoostingClassifier(random_state=0)\n","  algoritmo.fit(X,y)\n","  feature_importances = algoritmo.feature_importances_\n","\n","  # Importância das variáveis de acordo com o algoritmo\n","\n","  df_importancias = pd.DataFrame(X.columns,columns=['Variável'])\n","  df_importancias['Importância'] = feature_importances\n","\n","  df_importancias = df_importancias[df_importancias['Importância'] > 0]\n","  return df_importancias\n","\n","def vars_selection(df,percentual_preenchimento,threshold,tamanho_amostragem):\n","  variaveis_publico = df.filter(like='_publico').columns.to_list()\n","  df_aux = df.loc[:, ~df.columns.str.endswith('_publico')]\n","  amostra = amostragem(df_aux, tamanho_amostragem)\n","\n","  metadata_df = pod_academy_generate_metadata(amostra)\n","\n","  # Avaliar preenchimento\n","  vars = metadata_df[metadata_df.percent_nulos <= percentual_preenchimento]['nome_variavel']\n","  # Avaliar correlaçao\n","  df_reduced, dropped_features = remove_highly_correlated_features(amostra[vars], threshold=threshold)\n","  # Avaliar variância - remover variáveis constantes\n","  table_01 = variancia(df_reduced, threshold=0)\n","\n","  vars_selected = table_01.columns.to_list()\n","  vars_df_final = vars_selected + variaveis_publico\n","  df_selected = df[vars_df_final]\n","\n","  df_importancias = feature_importance(df_selected)\n","\n","  return df_importancias"]},{"cell_type":"markdown","metadata":{"id":"2-gaONBKX4Y2"},"source":["## 3.0 Leitura dos dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0WC_EcSX6ve"},"outputs":[],"source":["df_treino_full = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Projetos/Modelo_Credito_Application /Conjunto_de_Dados_Tratados/treino_full.csv')"]},{"cell_type":"markdown","metadata":{"id":"RGqKGyLGXke6"},"source":["## 4.0 Seleção de variáveis"]},{"cell_type":"markdown","source":["Esse comando executa o processo completo de seleção de variáveis no DataFrame df_treino_full, aplicando as etapas definidas anteriormente nas funções auxiliares.\n","\n","O parâmetro percentual_preenchimento=80 define que apenas variáveis com até 20% de valores ausentes serão consideradas. O threshold=0.5 define o limite máximo de correlação permitido entre variáveis — colunas mais correlacionadas que isso serão removidas para evitar redundância. Já tamanho_amostragem=85000 indica que o processo será feito com uma amostra de 85 mil registros do conjunto, reduzindo o custo computacional.\n","\n","No fim, a função retorna um DataFrame (df) com as variáveis mais relevantes identificadas pelo modelo de Gradient Boosting, ou seja, aquelas que têm maior impacto na previsão da variável alvo (TARGET_publico). Esse resultado é uma base otimizada e pronta para uso na modelagem preditiva."],"metadata":{"id":"Cz_LDZ6__6dV"}},{"cell_type":"code","source":["df = vars_selection(df_treino_full,percentual_preenchimento=80,threshold=0.5,tamanho_amostragem=85000)"],"metadata":{"id":"5poFVCGKcIJQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Esse trecho finaliza o processo de seleção de variáveis, mantendo apenas as colunas consideradas mais relevantes pelo modelo.\n","\n","Primeiro, ele cria uma lista (vars_selected) com os nomes das variáveis escolhidas a partir do DataFrame df, que contém o resultado da análise de importância das features. Em seguida, adiciona as colunas de identificação e alvo — SK_ID_CURR_publico e TARGET_publico — para garantir que o conjunto de dados continue completo para modelagem.\n","\n","Por fim, o comando exporta esse subconjunto do DataFrame original (df_treino_full) para um arquivo CSV chamado treino_full_vars_selecionadas.csv, armazenado no diretório especificado no Google Drive. O resultado é uma base limpa, reduzida e pronta para uso na etapa de treinamento e validação do modelo de crédito."],"metadata":{"id":"uI7UQTBkADMD"}},{"cell_type":"code","source":["# Manter apenas as variáveis selecionadas\n","vars_selected = df['Variável'].to_list()\n","vars_selected.append('SK_ID_CURR_publico')\n","vars_selected.append('TARGET_publico')\n","df_treino_full[vars_selected].to_csv(f'/content/drive/MyDrive/Colab Notebooks/Projetos/Modelo_Credito_Application /Conjunto_de_Dados_Tratados/treino_full_vars_selecionadas.csv', index=False)"],"metadata":{"id":"2RGR1nfrsM9i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Esse código aplica o mesmo processo de seleção de variáveis na base de teste, garantindo que ela mantenha exatamente as mesmas colunas usadas no treinamento.\n","\n","Primeiro, a base de teste completa é carregada a partir do arquivo teste_full.csv. Em seguida, a variável-alvo (TARGET_publico) é removida da lista vars_selected, já que ela só existe na base de treino. Por fim, o código filtra df_teste_full para manter apenas as variáveis selecionadas no modelo (df['Variável']) e salva o resultado em um novo arquivo chamado teste_full_vars_selecionadas.csv.\n","\n","Assim, tanto a base de treino quanto a de teste ficam padronizadas, contendo exatamente as mesmas variáveis — condição essencial para garantir consistência e comparabilidade nas etapas de predição e validação do modelo."],"metadata":{"id":"ALzTTGoTALIc"}},{"cell_type":"code","source":["# Realizar o mesmo procedimento na base de teste\n","df_teste_full = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Projetos/Modelo_Credito_Application /Conjunto_de_Dados_Tratados/teste_full.csv')\n","vars_selected.remove('TARGET_publico')\n","df_teste_full[df['Variável']].to_csv(f'/content/drive/MyDrive/Colab Notebooks/Projetos/Modelo_Credito_Application /Conjunto_de_Dados_Tratados/teste_full_vars_selecionadas.csv', index=False)"],"metadata":{"id":"2vo7UgqOtade"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Esse trecho cria e exibe a lista final de variáveis que serão mantidas para a modelagem.\n","\n","Primeiro, ele extrai os nomes das colunas mais importantes do DataFrame df, que contém o resultado da análise de importância das variáveis (df['Variável']). Em seguida, adiciona as colunas SK_ID_CURR_publico (identificador do cliente) e TARGET_publico (variável-alvo) para garantir que o conjunto de dados continue completo.\n","\n","Por fim, o comando vars_selected exibe a lista completa com todas as variáveis selecionadas, que será usada para filtrar o DataFrame de treino e teste antes de salvar as bases finais."],"metadata":{"id":"_Oisi7yRASy6"}},{"cell_type":"code","source":["vars_selected = df['Variável'].to_list()\n","vars_selected.append('SK_ID_CURR_publico')\n","vars_selected.append('TARGET_publico')\n","vars_selected"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"klZN9f-IvhqT","outputId":"905a9c3e-7026-4264-90ad-51cd41657e52"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['VL_MIN_VL_MIN_AMT_CREDIT_MAX_OVERDUE_ULTIMOS_12_MESES_externos',\n"," 'VL_MAX_VL_MIN_AMT_CREDIT_SUM_DEBT_ULTIMOS_6_MESES_externos',\n"," 'QT_MIN_QT_MIN_DAYS_CREDIT_ENDDATE_ULTIMOS_6_MESES_externos',\n"," 'VL_MIN_AMT_DOWN_PAYMENT_ULTIMOS_12_MESES_PREVIOUS_APPLICATION_internos',\n"," 'VL_MED_VL_MIN_AMT_CREDIT_SUM_OVERDUE_ULTIMOS_6_MESES_externos',\n"," 'QT_MIN_QT_MIN_CREDIT_DAY_OVERDUE_ULTIMOS_6_MESES_externos',\n"," 'VL_MIN_VL_MAX_CNT_CREDIT_PROLONG_ULTIMOS_6_MESES_externos',\n"," 'VL_TOT_VL_TOT_CNT_INSTALMENT_ULTIMOS_3_MESES_POS_CASH_ULTIMOS_12_MESES_PREVIOUS_APPLICATION_internos',\n"," 'QT_MAX_QT_MAX_SK_DPD_ULTIMOS_3_MESES_POS_CASH_ULTIMOS_12_MESES_PREVIOUS_APPLICATION_internos',\n"," 'QT_MIN_QT_MIN_SK_DPD_DEF_ULTIMOS_3_MESES_POS_CASH_ULTIMOS_12_MESES_PREVIOUS_APPLICATION_internos',\n"," 'VL_TOT_ULTIMOS_3_MESES_ULTIMOS_6_MESES_PREVIOUS_APPLICATION_internos',\n"," 'VL_MIN_HOUR_APPR_PROCESS_START_ULTIMOS_6_MESES_PREVIOUS_APPLICATION_internos',\n"," 'VL_MAX_QTD_STATUS_5_ULTIMOS_24_MESES_externos',\n"," 'VL_TOT_QTD_STATUS_5_ULTIMOS_3_MESES_externos',\n"," 'QT_MIN_QT_MAX_DAYS_ENTRY_PAYMENT_ULTIMOS_3_MESES_INSTALLMENTS_ULTIMOS_12_MESES_PREVIOUS_APPLICATION_internos',\n"," 'VL_TOT_VL_MIN_AMT_PAYMENT_ULTIMOS_3_MESES_INSTALLMENTS_ULTIMOS_12_MESES_PREVIOUS_APPLICATION_internos',\n"," 'QT_MIN_QT_MIN_DAYS_ENTRY_PAYMENT_ULTIMOS_3_MESES_INSTALLMENTS_ULTIMOS_12_MESES_PREVIOUS_APPLICATION_internos',\n"," 'VL_TOT_VL_TOT_NUM_INSTALMENT_VERSION_ULTIMOS_3_MESES_INSTALLMENTS_ULTIMOS_12_MESES_PREVIOUS_APPLICATION_internos',\n"," 'QT_MAX_QT_MIN_DAYS_INSTALMENT_ULTIMOS_3_MESES_INSTALLMENTS_ULTIMOS_12_MESES_PREVIOUS_APPLICATION_internos',\n"," 'VL_MIN_VL_TOT_NUM_INSTALMENT_NUMBER_ULTIMOS_3_MESES_INSTALLMENTS_ULTIMOS_12_MESES_PREVIOUS_APPLICATION_internos',\n"," 'QT_MAX_QT_MAX_DAYS_ENDDATE_FACT_ULTIMOS_24_MESES_externos',\n"," 'QT_MAX_DAYS_FIRST_DUE_ULTIMOS_12_MESES_PREVIOUS_APPLICATION_internos',\n"," 'QT_MAX_DAYS_TERMINATION_ULTIMOS_12_MESES_PREVIOUS_APPLICATION_internos',\n"," 'VL_TOT_VL_MED_ULTIMOS_24_MESES_ULTIMOS_3_MESES_POS_CASH_ULTIMOS_24_MESES_PREVIOUS_APPLICATION_internos',\n"," 'QT_MIN_QT_MAX_DAYS_CREDIT_UPDATE_ULTIMOS_12_MESES_externos',\n"," 'QT_MIN_QT_MAX_DAYS_ENDDATE_FACT_ULTIMOS_36_MESES_externos',\n"," 'VL_MIN_AMT_CREDIT_ULTIMOS_12_MESES_PREVIOUS_APPLICATION_internos',\n"," 'VL_TOT_VL_TOT_CNT_CREDIT_PROLONG_ULTIMOS_24_MESES_externos',\n"," 'QT_MAX_DAYS_LAST_DUE_1ST_VERSION_ULTIMOS_24_MESES_PREVIOUS_APPLICATION_internos',\n"," 'QT_MIN_DAYS_FIRST_DUE_ULTIMOS_24_MESES_PREVIOUS_APPLICATION_internos',\n"," 'QT_MAX_DAYS_FIRST_DRAWING_ULTIMOS_24_MESES_PREVIOUS_APPLICATION_internos',\n"," 'VL_MED_ULTIMOS_12_MESES_ULTIMOS_24_MESES_PREVIOUS_APPLICATION_internos',\n"," 'VL_MIN_ULTIMOS_6_MESES_ULTIMOS_24_MESES_PREVIOUS_APPLICATION_internos',\n"," 'QT_MIN_DAYS_LAST_DUE_ULTIMOS_36_MESES_PREVIOUS_APPLICATION_internos',\n"," 'VL_MIN_ULTIMOS_24_MESES_ULTIMOS_36_MESES_PREVIOUS_APPLICATION_internos',\n"," 'AMT_INCOME_TOTAL_publico',\n"," 'AMT_CREDIT_publico',\n"," 'AMT_ANNUITY_publico',\n"," 'AMT_GOODS_PRICE_publico',\n"," 'REGION_POPULATION_RELATIVE_publico',\n"," 'DAYS_BIRTH_publico',\n"," 'DAYS_EMPLOYED_publico',\n"," 'DAYS_REGISTRATION_publico',\n"," 'DAYS_ID_PUBLISH_publico',\n"," 'OWN_CAR_AGE_publico',\n"," 'FLAG_WORK_PHONE_publico',\n"," 'REGION_RATING_CLIENT_W_CITY_publico',\n"," 'REG_CITY_NOT_LIVE_CITY_publico',\n"," 'EXT_SOURCE_1_publico',\n"," 'EXT_SOURCE_2_publico',\n"," 'EXT_SOURCE_3_publico',\n"," 'YEARS_BUILD_AVG_publico',\n"," 'ENTRANCES_AVG_publico',\n"," 'LANDAREA_AVG_publico',\n"," 'NONLIVINGAREA_AVG_publico',\n"," 'YEARS_BEGINEXPLUATATION_MODE_publico',\n"," 'YEARS_BUILD_MODE_publico',\n"," 'COMMONAREA_MODE_publico',\n"," 'LANDAREA_MODE_publico',\n"," 'LIVINGAPARTMENTS_MODE_publico',\n"," 'NONLIVINGAPARTMENTS_MODE_publico',\n"," 'NONLIVINGAREA_MODE_publico',\n"," 'YEARS_BEGINEXPLUATATION_MEDI_publico',\n"," 'COMMONAREA_MEDI_publico',\n"," 'ELEVATORS_MEDI_publico',\n"," 'FLOORSMAX_MEDI_publico',\n"," 'NONLIVINGAREA_MEDI_publico',\n"," 'TOTALAREA_MODE_publico',\n"," 'DEF_30_CNT_SOCIAL_CIRCLE_publico',\n"," 'DEF_60_CNT_SOCIAL_CIRCLE_publico',\n"," 'DAYS_LAST_PHONE_CHANGE_publico',\n"," 'FLAG_DOCUMENT_2_publico',\n"," 'FLAG_DOCUMENT_3_publico',\n"," 'FLAG_DOCUMENT_16_publico',\n"," 'AMT_REQ_CREDIT_BUREAU_HOUR_publico',\n"," 'AMT_REQ_CREDIT_BUREAU_DAY_publico',\n"," 'AMT_REQ_CREDIT_BUREAU_QRT_publico',\n"," 'AMT_REQ_CREDIT_BUREAU_YEAR_publico',\n"," 'var_1_publico',\n"," 'var_2_publico',\n"," 'var_3_publico',\n"," 'var_5_publico',\n"," 'var_6_publico',\n"," 'var_7_publico',\n"," 'var_8_publico',\n"," 'var_9_publico',\n"," 'var_10_publico',\n"," 'var_11_publico',\n"," 'var_12_publico',\n"," 'var_13_publico',\n"," 'var_14_publico',\n"," 'var_15_publico',\n"," 'var_16_publico',\n"," 'var_17_publico',\n"," 'var_18_publico',\n"," 'var_19_publico',\n"," 'var_20_publico',\n"," 'var_21_publico',\n"," 'var_22_publico',\n"," 'var_23_publico',\n"," 'var_24_publico',\n"," 'var_25_publico',\n"," 'var_27_publico',\n"," 'var_28_publico',\n"," 'var_29_publico',\n"," 'var_31_publico',\n"," 'var_32_publico',\n"," 'var_33_publico',\n"," 'var_34_publico',\n"," 'var_35_publico',\n"," 'var_36_publico',\n"," 'var_37_publico',\n"," 'var_38_publico',\n"," 'var_39_publico',\n"," 'var_40_publico',\n"," 'var_44_publico',\n"," 'var_45_publico',\n"," 'var_47_publico',\n"," 'var_48_publico',\n"," 'var_49_publico',\n"," 'var_50_publico',\n"," 'CODE_GENDER_publico',\n"," 'FLAG_OWN_CAR_publico',\n"," 'NAME_INCOME_TYPE_publico',\n"," 'NAME_EDUCATION_TYPE_publico',\n"," 'OCCUPATION_TYPE_publico',\n"," 'WEEKDAY_APPR_PROCESS_START_publico',\n"," 'ORGANIZATION_TYPE_publico',\n"," 'SK_ID_CURR_publico',\n"," 'TARGET_publico']"]},"metadata":{},"execution_count":31}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
